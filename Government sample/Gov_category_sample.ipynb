{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    \"/Users/sofiepalmuskronborg/Desktop/Speciale/Data/deberta_top_labels.csv\",\n",
    "    index_col=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroshot_classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"MoritzLaurer/deberta-v3-large-zeroshot-v1.1-all-33\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gov_sample = data[data[\"top_label\"] == \"Government\"].sample(n=1000)\n",
    "gov_sample = gov_sample.drop(['labels','scores', 'top_label', 'top_score'],axis=1)\n",
    "# gov_sample.to_csv(\"1000_gov.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_template = \"This ad is about {}\"\n",
    "classes_verbalized = [\n",
    "    \"Economy\",\n",
    "    \"Civil Rights\",\n",
    "    \"Healthcare\",\n",
    "    \"Agriculture\",\n",
    "    \"Labor and Employment\",\n",
    "    \"Education and Culture\",\n",
    "    \"Climate\",\n",
    "    \"Immigration\",\n",
    "    \"Transport\",\n",
    "    \"Law and Crime\",\n",
    "    \"Social Welfare\",\n",
    "    \"Housing\",\n",
    "    \"Defense\",\n",
    "    \"Foreign Affair\",\n",
    "    \"Government\",\n",
    "    \"Call for action\"  # new\n",
    "    \"Other\",  # placeholder category\n",
    "]  #\n",
    "\n",
    "# output = zeroshot_classifier(\n",
    "#    text, classes_verbalized, hypothesis_template=hypothesis_template, multi_label=False\n",
    "# )\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_vector = {}  # dict to store the model outcome\n",
    "\n",
    "for text in gov_sample[\"ad_creative_body\"]:\n",
    "    hypo = f\"This ad is about {{}}\"\n",
    "    output = zeroshot_classifier(\n",
    "        text,\n",
    "        classes_verbalized,\n",
    "        hypothesis_template=hypothesis_template,\n",
    "        multi_label=False,\n",
    "    )\n",
    "    text_to_vector[text] = {\n",
    "        \"labels\": output[\n",
    "            \"labels\"\n",
    "        ],  # keep all labels and their corresponding scores in a list format\n",
    "        \"scores\": output[\"scores\"],\n",
    "    }\n",
    "\n",
    "# Making two new columns\n",
    "gov_sample[\"labels\"] = gov_sample[\"ad_creative_body\"].map(\n",
    "    lambda text: text_to_vector[text][\"labels\"]\n",
    ")\n",
    "gov_sample[\"scores\"] = gov_sample[\"ad_creative_body\"].map(\n",
    "    lambda text: text_to_vector[text][\"scores\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort away duplicate ad texts coming from the same politician\n",
    "gov_label_data_unik = gov_sample.drop_duplicates(subset=[\"ad_creative_body\", \"page_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts 'labels' and 'scores' column from object to a list to be able to retrieve the first instance -> top score/top_label\n",
    "\n",
    "gov_label_data_unik[\"labels\"] = gov_label_data_unik[\"labels\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "gov_label_data_unik[\"scores\"] = gov_label_data_unik[\"scores\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "# Retrieving first instance in each column\n",
    "gov_label_data_unik[\"top_label\"] = gov_label_data_unik[\"labels\"].str[0]\n",
    "gov_label_data_unik[\"top_score\"] = gov_label_data_unik[\"scores\"].str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for Gov sample with addition of 'Call for Action' category:\n",
      "\n",
      "Call for action: 555 ads (55.50%)\n",
      "Government: 441 ads (44.10%)\n",
      "Transport: 3 ads (0.30%)\n",
      "Healthcare: 1 ads (0.10%)\n"
     ]
    }
   ],
   "source": [
    "top_labels_sample = (gov_label_data_unik[\"top_label\"].value_counts()).iloc[\n",
    "    :16\n",
    "]  # all labels for sample\n",
    "\n",
    "# calcu the amount + % for each top\n",
    "top_percentages = (\n",
    "    gov_label_data_unik[\"top_label\"].value_counts(normalize=True).iloc[:16]\n",
    ") * 100\n",
    "\n",
    "# Print the total counts and %\n",
    "print(\"Stats for Gov sample with addition of 'Call for Action' category:\\n\")\n",
    "for label, count, percentage in zip(\n",
    "    top_labels_sample.index, top_labels_sample.values, top_percentages.values\n",
    "):\n",
    "    print(f\"{label}: {count} ads ({percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gov_label_data_unik.to_csv(\"1000_sample_gov_cfa.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
